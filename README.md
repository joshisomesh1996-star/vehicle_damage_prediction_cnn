# ğŸš— Vehicle Damage Detection

A lightweight computerâ€‘vision pipeline that identifies six common damage categories from a single car photo:

| Label            | Description                              |
| ---------------- | ---------------------------------------- |
| `Frontâ€¯Breakage` | Visible fractures on front bumper/grille |
| `Frontâ€¯Crushed`  | Severe front deformation / crumple       |
| `Frontâ€¯Normal`   | No frontâ€‘side damage                     |
| `Rearâ€¯Breakage`  | Visible fractures on rear bumper         |
| `Rearâ€¯Crushed`   | Severe rear deformation / crumple        |
| `Rearâ€¯Normal`    | No rearâ€‘side damage                      |

The project contains three main layers:

1. **`app.py`** â€“ a Streamlit frontend for dragâ€‘andâ€‘drop inference (no external services required).
2. **`model_helper.py`** â€“ wraps a fineâ€‘tuned **ResNetâ€‘50** and handles image transforms + predictions.
3. **Jupyter notebooks** â€“ exploratory training and Optunaâ€‘based hyperâ€‘parameter tuning.

---

## ğŸ“¸Â Screenshots

<p align="center">
  <img src="screenshots/1.png" width="360" alt="Home screen">
  <img src="screenshots/2.png" width="360" alt="Prediction result">
</p>

---

## ğŸ—‚ï¸Â Repository layout

```text
vehicle-damage-prediction/
â”œâ”€ app.py                     â† Streamlit UI
â”œâ”€ server.py                  â† Minimal FastAPI stub (optional deployment)
â”œâ”€ model_helper.py            â† ResNet50 wrapper + `predict()` function
â”œâ”€ model/                     â† Trained weights  âœ  model/saved_model.pth
â”œâ”€ damage_prediction.ipynb    â† Endâ€‘toâ€‘end modelling & evaluation
â”œâ”€ hyperparameter_tunning.ipynb
â”œâ”€ test_images/               â† Handy samples for quick testing
â”œâ”€ screenshots/               â† Two default images for README
â”œâ”€ requirements.txt
â””â”€ README.md                  â† Youâ€™re here
```

---

## ğŸ“’Â Notebook summaries

### 1. `damage_prediction.ipynb`

| Section                            | Highlights                                                                                                         |
| ---------------------------------- | ------------------------------------------------------------------------------------------------------------------ |
| **Load Data**                      | Uses `torchvision.datasets.ImageFolder` with custom `transforms` (resizeâ€¯224Ã—224, randomâ€‘flip, randomâ€‘rotation).   |
| **ModelÂ 1 â€“ PlainÂ CNN**            | Baseline 3â€‘convâ€‘block network built from scratch in **PyTorch**.                                                   |
| **ModelÂ 2 â€“ CNNÂ +Â Regularisation** | Adds dropout + batchâ€‘norm to curb overfitting.                                                                     |
| **ModelÂ 3 â€“ EfficientNetâ€‘B0**      | Transferâ€‘learns on ImageNet weights; faster convergence but slightly lower recall on minority classes.             |
| **ModelÂ 4 â€“ ResNetâ€‘50**            | Best topâ€‘1 validation accuracy (\~80â€¯%). Layerâ€‘4 unfrozen, final FC replaced with `Dropout(0.5) â†’ Linear(2048â†’6)`. |
| **Evaluation**                     | Confusionâ€‘matrix + classification report (precision/recall/F1).                                                    |
| **SaveÂ Model**                     | Persists weights to `model/saved_model.pth` for use in the Streamlit app.                                          |

### 2. `hyperparameter_tunning.ipynb`

* Implements **Optuna** for Bayesian optimisation.
* Search space:

  * LearningÂ rateâ€¯âˆˆâ€¯\[1eâ€‘5,â€¯1eâ€‘2] (logâ€‘uniform)
  * Dropoutâ€¯âˆˆâ€¯\[0.2,â€¯0.7]
* Objective: maximise validation accuracy on a **20â€¯% holdâ€‘out split**.
* Best trial: **lrâ€¯=â€¯0.005**, **dropoutâ€¯=â€¯0.20** â€“ echoed back into the main notebook for the final training run.

---

## ğŸš€Â Quick start

```bash
# 1. install deps
pip install -r requirements.txt

# 2. launch Streamlit
streamlit run app.py
```

The interface accepts **.jpg / .png** images, displays a preview, and shows the predicted class in an infoâ€‘box.

> **Tip:** on first inference the model is loaded lazily; subsequent predictions are instant.

---

## ğŸ› ï¸Â Training from scratch (optional)

1. Place your dataset in `./dataset/<class_name>/image.jpg` folder structure
2. Open `damage_prediction.ipynb`, run all cells (GPU recommended)
3. Weights will autoâ€‘save to `model/saved_model.pth`
4. Launch the app as shown above â€“ it will pick up the new weights automatically.

---

## ğŸ¤Â Contributing

Pull requests and issue reports are welcome!

---

## ğŸ“„Â License

Distributed under the **MIT License** â€“ see `LICENSE` for details.
